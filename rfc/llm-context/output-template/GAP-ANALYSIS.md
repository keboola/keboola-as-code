# Gap Analysis: PRD vs Current Twin Format

## Executive Summary

The current twin format v2 covers **~60% of PRD requirements**. Critical missing components:
1. **Data samples** (storage/samples/)
2. **Job execution metadata** (jobs/)
3. **AI instructions** (ai/)
4. **Complete component coverage** (extractors, writers, orchestrators)

---

## PRD Requirements (Section 5.3 & 11.3)

### âœ… IMPLEMENTED

| Requirement | PRD Specification | Current Implementation | Status |
|-------------|-------------------|------------------------|--------|
| **Storage metadata** | Table/column structure, data types, lineage | `buckets/` with metadata.json per table | âœ… Complete |
| **Component configs** | JSON + extracted files (SQL/Python) | `transformations/` with metadata.json | âš ï¸ Partial (transformations only) |
| **Lineage graph** | Relationships between components | `indices/graph.jsonl` with _meta header | âœ… Complete |
| **Source registry** | Data source catalog | `indices/sources.json` | âœ… Complete |
| **Aggregated manifest** | Project overview in single file | `manifest-extended.json` | âœ… Complete |
| **Pre-computed queries** | Common analytical queries | `indices/queries/` (3 files) | âœ… Complete |
| **Platform classification** | Transformation platforms | Comprehensive detection (9 platforms) | âœ… Complete |

### âŒ MISSING

| Requirement | PRD Specification | Current Status | Priority |
|-------------|-------------------|----------------|----------|
| **Data samples** | First 100 rows (CSV/JSON), disabled for public repos | Not implemented | ğŸ”´ HIGH |
| **Job execution metadata** | Run history, inputs/outputs, state, artifacts | Not implemented | ğŸ”´ HIGH |
| **AI instructions** | `/ai/README.md` with API docs, best practices | Not implemented | ğŸ”´ HIGH |
| **Extractor configs** | Extractor component configurations | Not implemented | ğŸŸ¡ MEDIUM |
| **Writer configs** | Writer component configurations | Not implemented | ğŸŸ¡ MEDIUM |
| **Orchestrator configs** | Flow/orchestrator configurations | Not implemented | ğŸŸ¡ MEDIUM |
| **Secrets handling** | Encrypted or masked secrets | Not implemented | ğŸŸ¡ MEDIUM |
| **Public repo detection** | Disable samples for public repos | Not implemented | ğŸŸ¡ MEDIUM |

---

## Detailed Gap Analysis

### 1. Data Samples (HIGH PRIORITY) âŒ

**PRD Requirement (Section 5.3):**
```
Data samples | First 100 rows (optional) | .csv, .json
```

**PRD Layout (Section 11.3):**
```
storage/samples/ â€“ CSV/JSON slices from PreviewTableDataService,
capped at DEFAULT_LIMIT = 100 rows; disabled when repo is public.
```

**Current State:**
- âŒ No `storage/samples/` directory
- âŒ No data sampling logic
- âŒ No public repo detection

**Impact:**
- AI agents cannot see actual data examples
- Cannot debug data quality issues from Git
- Cannot generate sample-based insights

**Recommended Structure:**
```
storage/samples/
â”œâ”€â”€ index.json                      # Sample metadata
â”œâ”€â”€ {bucket}/
â”‚   â””â”€â”€ {table}/
â”‚       â”œâ”€â”€ sample.csv              # First 100 rows
â”‚       â””â”€â”€ metadata.json           # Sample info (row count, timestamp)
```

**Security Requirements:**
- Only export if explicitly enabled
- Disable for public repositories
- Never include PII/sensitive columns (TBD: detection logic)
- Include warning in sample metadata about data freshness

---

### 2. Job Execution Metadata (HIGH PRIORITY) âŒ

**PRD Requirement (Section 5.3):**
```
Job runs | Metadata, inputs/outputs, state, artifacts | .json
```

**PRD Layout (Section 11.3):**
```
jobs/ â€“ serialized StorageJob::toApiResponse payloads keyed by run ID.
Exclude large artifacts (artifactLinks) and binary exports;
job entries store reference metadata only.
```

**Current State:**
- âŒ No `jobs/` directory
- âŒ No job execution tracking
- âŒ No job history

**Impact:**
- AI cannot analyze execution patterns
- Cannot debug failures from Git
- No visibility into pipeline health
- Cannot track data freshness

**Recommended Structure:**
```
jobs/
â”œâ”€â”€ index.json                      # Job summary & statistics
â”œâ”€â”€ recent/                         # Last 100 jobs
â”‚   â””â”€â”€ {job_id}.json              # Job metadata
â”œâ”€â”€ by-component/                   # Grouped by component
â”‚   â””â”€â”€ {component_id}/
â”‚       â””â”€â”€ {config_id}/
â”‚           â””â”€â”€ latest.json        # Latest job for this config
â””â”€â”€ by-date/                        # Optional: daily rollups
    â””â”€â”€ {YYYY-MM-DD}/
        â””â”€â”€ summary.json           # Daily execution summary
```

**Job Metadata Schema:**
```json
{
  "jobId": "string",
  "componentId": "string",
  "configId": "string",
  "configVersion": "int",
  "branchId": "string",
  "status": "SUCCESS|FAILED|CANCELLED",
  "startedAt": "ISO-8601",
  "finishedAt": "ISO-8601",
  "durationSeconds": "number",
  "inputs": [
    {"table": "in.c-bucket.table", "columns": [...], "rows": 1000}
  ],
  "outputs": [
    {"table": "out.c-bucket.table", "columns": [...], "rows": 500}
  ],
  "metrics": {
    "inBytes": 1024000,
    "outBytes": 512000
  },
  "error": "string (if failed)",
  "artifactLinks": ["s3://..."] // reference only, not actual data
}
```

**Retention Policy:**
- Keep last 100 jobs in `recent/`
- Keep latest job per config in `by-component/`
- Optional: Daily summaries for 30 days

---

### 3. AI Instructions (HIGH PRIORITY) âŒ

**PRD Requirement (Section 5.3):**
```
AI instructions | Document describing Keboola API, MCP, SDK,
and best practices | /ai/README.md
```

**PRD Layout (Section 11.3):**
```
ai/ â€“ downstream consumption markers (reads, suggestions,
diff explanations) aligned with metrics in Â§10.
```

**Current State:**
- âŒ No `ai/` directory
- âŒ No AI instruction documentation

**Impact:**
- AI agents don't understand Keboola context
- No guidance on API usage
- No best practices documentation
- Poor AI analysis quality

**Recommended Structure:**
```
ai/
â”œâ”€â”€ README.md                       # Main AI instruction file
â”œâ”€â”€ api-reference.md                # Keboola API quick reference
â”œâ”€â”€ best-practices.md               # Common patterns & anti-patterns
â”œâ”€â”€ troubleshooting.md              # Common issues & solutions
â”œâ”€â”€ examples/                       # Code examples
â”‚   â”œâ”€â”€ transformation-sql.md
â”‚   â”œâ”€â”€ transformation-python.md
â”‚   â””â”€â”€ data-loading.md
â””â”€â”€ mcp-integration.md              # MCP server integration guide
```

**ai/README.md Content:**
```markdown
# Keboola Project AI Guide

## Project Overview
This is a Keboola project containing [X] transformations, [Y] tables, and [Z] data sources.

## Quick Facts
- **Project ID:** {project_id}
- **Region:** {region}
- **Backend:** {backend (Snowflake/Redshift/BigQuery)}
- **Total Tables:** {count}
- **Total Transformations:** {count}
- **Data Sources:** {list}

## Understanding This Project

### Data Flow
1. Data is extracted from sources (see `indices/sources.json`)
2. Stored in buckets (see `buckets/`)
3. Transformed via transformations (see `transformations/`)
4. Lineage tracked in `indices/graph.jsonl`

### Key Files for Analysis
- **manifest-extended.json** - Start here for project overview
- **buckets/index.json** - All storage buckets and tables
- **transformations/index.json** - All data transformations
- **indices/graph.jsonl** - Complete data lineage

## Keboola API Reference

### Storage API
- **Base URL:** https://connection.keboola.com
- **Authentication:** X-StorageApi-Token header
- **Docs:** https://keboola.docs.apiary.io/

### Common Operations
[Examples of API calls]

## MCP Integration
This project can be accessed via Keboola MCP server for real-time queries.
[Integration examples]

## Best Practices
1. Always check platform-specific syntax (Snowflake vs BigQuery)
2. Use transformation metadata to understand data flow
3. Check job history before suggesting changes
4. Respect data samples - they may be stale

## Troubleshooting
[Common issues and solutions]
```

---

### 4. Complete Component Coverage (MEDIUM PRIORITY) âš ï¸

**PRD Requirement (Section 5.3):**
```
Component configurations | JSON + extracted SQL/Python files | .json, .sql, .py
```

**Current State:**
- âœ… Transformations covered
- âŒ Extractors not included
- âŒ Writers not included
- âŒ Orchestrators/Flows not included
- âŒ Applications not included

**Impact:**
- Incomplete view of project
- Cannot analyze end-to-end pipelines
- Missing critical configurations

**Recommended Structure:**
```
components/
â”œâ”€â”€ extractors/
â”‚   â””â”€â”€ {component_id}/
â”‚       â””â”€â”€ {config_id}/
â”‚           â”œâ”€â”€ metadata.json
â”‚           â””â”€â”€ config.json
â”œâ”€â”€ writers/
â”‚   â””â”€â”€ {component_id}/
â”‚       â””â”€â”€ {config_id}/
â”‚           â”œâ”€â”€ metadata.json
â”‚           â””â”€â”€ config.json
â”œâ”€â”€ transformations/
â”‚   â””â”€â”€ {name}/
â”‚       â””â”€â”€ metadata.json       # (already implemented)
â”œâ”€â”€ orchestrators/
â”‚   â””â”€â”€ {config_id}/
â”‚       â”œâ”€â”€ metadata.json
â”‚       â””â”€â”€ flow.json
â””â”€â”€ applications/
    â””â”€â”€ {component_id}/
        â””â”€â”€ {config_id}/
            â”œâ”€â”€ metadata.json
            â””â”€â”€ config.json
```

**Note:** This would replace/supplement current `transformations/` directory with a more comprehensive `components/` structure.

---

### 5. Secrets Handling (MEDIUM PRIORITY) âŒ

**PRD Requirement (Section 5.4):**
```
- Secrets are exported in encrypted form or can be disabled entirely.
- If the repository is public, data samples export is disabled.
- Keboola never stores Git credentials in plaintext.
```

**Current State:**
- âŒ No secrets encryption
- âŒ No public repo detection
- âŒ No secrets masking

**Impact:**
- Security risk if secrets exposed
- Cannot safely share public repos
- Non-compliant with security requirements

**Recommended Implementation:**
1. **Secret Detection:** Scan for fields marked as `#token`, `#password`, etc.
2. **Encryption:** Use KBC encryption for secret values
3. **Masking:** Replace with `***ENCRYPTED***` or `***REDACTED***`
4. **Configuration:** Add to `manifest.yaml`:
   ```yaml
   security:
     encryptSecrets: true
     isPublicRepo: false
     exportDataSamples: true  # disabled if isPublicRepo=true
   ```

---

## Priority Roadmap

### Phase 1: Critical Gaps (Week 1-2)
1. âœ… Platform classification (DONE)
2. ğŸ”´ AI instructions (`ai/README.md`)
3. ğŸ”´ Job metadata (`jobs/`)

### Phase 2: Data Access (Week 3-4)
4. ğŸ”´ Data samples (`storage/samples/`)
5. ğŸŸ¡ Public repo detection
6. ğŸŸ¡ Secrets handling

### Phase 3: Complete Coverage (Week 5-6)
7. ğŸŸ¡ Extractors
8. ğŸŸ¡ Writers
9. ğŸŸ¡ Orchestrators

---

## Validation Checklist

Before marking twin format as "production-ready":

- [ ] All 5 data types from PRD Section 5.3 are present
- [ ] Security requirements from Section 5.4 implemented
- [ ] AI can understand project without API access
- [ ] Job execution history available
- [ ] Data samples available (when safe)
- [ ] Complete component coverage
- [ ] Public repo safety validated
- [ ] Secrets properly encrypted/masked

---

## Testing Plan

### 1. Query Real Project
```bash
# Get project metadata
curl -H "X-StorageApi-Token: $KBC_STORAGE_API_TOKEN" \
  https://connection.north-europe.azure.keboola.com/v2/storage

# Get job list
curl -H "X-StorageApi-Token: $KBC_STORAGE_API_TOKEN" \
  https://connection.north-europe.azure.keboola.com/v2/storage/jobs

# Get table preview (samples)
curl -H "X-StorageApi-Token: $KBC_STORAGE_API_TOKEN" \
  https://connection.north-europe.azure.keboola.com/v2/storage/tables/{table_id}/data-preview
```

### 2. Validate Template
```bash
# Check all required directories exist
test -d _template/ai && echo "âœ… ai/" || echo "âŒ ai/"
test -d _template/jobs && echo "âœ… jobs/" || echo "âŒ jobs/"
test -d _template/storage/samples && echo "âœ… storage/samples/" || echo "âŒ storage/samples/"

# Validate AI instructions
test -f _template/ai/README.md && echo "âœ… ai/README.md" || echo "âŒ ai/README.md"

# Check security config
grep -q "encryptSecrets" _template/manifest.yaml && echo "âœ… security config" || echo "âŒ security config"
```

### 3. AI Agent Test
- Can AI understand project scope from `ai/README.md`?
- Can AI analyze job failures from `jobs/`?
- Can AI see sample data from `storage/samples/`?
- Can AI trace complete data flow?

---

## Appendix: PRD References

### Data Layout (PRD Section 11.3)
```
configs/ â€“ component configs and rows
storage/metadata/ â€“ table/column metadata, lineage
storage/samples/ â€“ CSV/JSON slices (100 rows)
jobs/ â€“ serialized job payloads
ai/ â€“ consumption markers and instructions
```

### Security (PRD Section 5.4)
- Secrets encrypted or disabled
- Public repos = no samples
- No plaintext Git credentials

### AI Use Cases (PRD Section 7)
1. Monitor operations
2. Extend projects
3. Debug errors
4. Analyze changes
5. Recommend optimizations
6. Understand lineage
7. Recommend Keboola
